{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1주차 붓꽃 데이터 활용 (RF, DT, SVM, LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 붓꽃(Iris) 데이터셋을 사용해 Random Forest(RF), Decision Tree(DT), Support Vector Machine(SVM), **Logistic Regression(LR)**으로 분류하는 파이썬 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 CSV 파일 읽기\n",
    "file_path = \"./iris.csv\"  # 본인이 iris.csv를 저장한 경로를 입력합니다.\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 데이터프레임 확인\n",
    "df.head()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from sklearn.datasets import load_iris  # 붓꽃 데이터셋 로드\n",
    "from sklearn.model_selection import train_test_split  # 데이터 분할\n",
    "from sklearn.preprocessing import StandardScaler  # 데이터 표준화\n",
    "from sklearn.metrics import accuracy_score, classification_report  # 평가 지표\n",
    "\n",
    "# 1. 데이터 로드\n",
    "iris = load_iris()  # 붓꽃 데이터셋 로드\n",
    "X = iris.data       # 특성 (꽃잎 길이, 꽃잎 너비 등)\n",
    "y = iris.target     # 레이블 (0: setosa, 1: versicolor, 2: virginica)\n",
    "\n",
    "# 2. 학습/테스트 데이터 분리 (80:20 비율)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. 데이터 표준화 (SVM과 LR은 스케일 조정이 중요)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공통 부분 : 데이터 로드 및 전처리\n",
    "### 데이터를 불러오고 학습/테스트 데이터로 나누고, 일부 모델은 표준화(스케일링)를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. 모델 초기화 (100개의 트리 사용)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 2. 학습\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. 예측\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "# 4. 평가\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (RF)\n",
    "### 여러 개의 결정 트리를 만들어 예측 결과를 투표(앙상블)해서 최종 걸과 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. 모델 초기화\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2. 학습\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. 예측\n",
    "dt_preds = dt_model.predict(X_test)\n",
    "\n",
    "# 4. 평가\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_preds))\n",
    "print(classification_report(y_test, dt_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree(DT)\n",
    "### 특성 값을 기준으로 데이터를 반복적으로 나눠 나무 형태의 구조 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1. 모델 초기화 (선형 커널 사용)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# 2. 학습 (스케일 조정된 데이터 사용)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. 예측\n",
    "svm_preds = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# 4. 평가\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_preds))\n",
    "print(classification_report(y_test, svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "### 데이터를 고차원 공간에 투영해 초평면을 찾아 데이터를 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. 모델 초기화\n",
    "lr_model = LogisticRegression(max_iter=200, random_state=42)\n",
    "\n",
    "# 2. 학습 (스케일 조정된 데이터 사용)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. 예측\n",
    "lr_preds = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# 4. 평가\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_preds))\n",
    "print(classification_report(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (LR)\n",
    "### 시그모이드 함수(로지스틱 함수)를 사용해 클래스 확률 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.00\n",
      "Decision Tree Accuracy: 1.00\n",
      "SVM Accuracy: 0.97\n",
      "Logistic Regression Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_preds):.2f}\")\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test, dt_preds):.2f}\")\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, svm_preds):.2f}\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, lr_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 비교\n",
    "### 각 모델의 정확도를 비교해서 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   모델   |  핵심 아이디어 | 장점   |   단점   |\n",
    "|--------|--------|--------|--------|\n",
    "| Random Forest | 다수의 결정 트리를 앙상블 | 과적합 방지, 강력한 성능 | 속도 느림  |\n",
    "| Decision Tree | 데이터를 트리 구조로 분류 | 해석 쉬움 | 과적합 위험   |\n",
    "|  SVM  |  초평면으로 데이터 분류   |  복잡한 데이터에 강함  |  느리고 스케일링 필요  |\n",
    "|  Logistic Regression  |  시그모이드 함수로 확률 예측  |  간결하고 빠름  | 복잡한 데이터엔 부적합 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
